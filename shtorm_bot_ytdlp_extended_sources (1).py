
import feedparser
import time
import requests
import re
import os
import subprocess
from bs4 import BeautifulSoup

BOT_TOKEN = "7992455449:AAFO-JyPCJ48tsAUwYyfZzhhW5hOnF-XyVw"
CHAT_ID = "@shtormnews"

# üîπ –¢–æ–ª—å–∫–æ –Ω–∞–¥—ë–∂–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ —Å —Ä–∞–±–æ—Ç–∞—é—â–∏–º –≤–∏–¥–µ–æ
RSS_FEEDS = [
    "https://russian.rt.com/rss",
    "https://www.vesti.ru/vesti.rss"
]

VIRAL_KEYWORDS = [
    "–ø–æ–∂–∞—Ä", "–≤–∑–æ—Ä–≤–∞–ª", "–∞—Ä–µ—Å—Ç", "–∑–∞–¥–µ—Ä–∂–∞–Ω", "–¥—Ç–ø", "–∞–≤–∞—Ä–∏—è",
    "—Ç–µ—Ä–∞–∫—Ç", "–≤–∑—Ä—ã–≤", "–æ–≥–æ–Ω—å", "—É–±–∏–π—Å—Ç–≤–æ", "Telegram",
    "–∑–≤–µ–∑–¥–∞", "–±–ª–æ–≥–µ—Ä", "—á–ø", "—Å–∫–∞–Ω–¥–∞–ª", "–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∞", "–ø–æ–ª–∏—Ü–∏—è"
]

posted_links = set()

headers = {
    "User-Agent": "Mozilla/5.0 (compatible; ShtormBot/1.0)"
}

def clean_html(raw_html):
    cleanr = re.compile('<.*?>')
    return re.sub(cleanr, '', raw_html).strip()

def summarize(text):
    clean = clean_html(text)
    sentences = re.split(r'[.!?]', clean)
    return sentences[0].strip() + "." if sentences else clean

def build_caption(title, description):
    title = f"<b>‚ö° {title.strip()}</b>"
    summary = summarize(description)
    if len(summary) > 300:
        summary = summary[:297] + "..."
    return f"{title}

{summary}

üì° @shtormnews"

def is_viral(title, description):
    text = (title + " " + description).lower()
    return any(kw in text for kw in VIRAL_KEYWORDS)

def extract_video_url(entry_url):
    try:
        r = requests.get(entry_url, headers=headers, timeout=10)
        soup = BeautifulSoup(r.text, 'html.parser')
        iframe = soup.find("iframe")
        if iframe and "src" in iframe.attrs:
            return iframe["src"]
    except Exception as e:
        print("–ù–µ —É–¥–∞–ª–æ—Å—å –∏–∑–≤–ª–µ—á—å iframe:", e)
    return entry_url  # fallback

def download_video(url, filename="video.mp4"):
    try:
        subprocess.run(
            ["yt-dlp", "-f", "mp4", "-o", filename, url],
            check=True,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.DEVNULL
        )
        return os.path.exists(filename)
    except Exception as e:
        print("–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –≤–∏–¥–µ–æ:", e)
        return False

def send_video_file(filename, caption):
    url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendVideo"
    with open(filename, 'rb') as video:
        files = {'video': video}
        data = {'chat_id': CHAT_ID, 'caption': caption, 'parse_mode': 'HTML'}
        r = requests.post(url, data=data, files=files)
        if r.status_code == 429:
            wait = int(re.findall(r'retry after (\d+)', r.text)[0])
            print(f"‚è≥ –ó–∞–¥–µ—Ä–∂–∫–∞ Telegram: {wait} —Å–µ–∫.")
            time.sleep(wait)
        elif r.status_code != 200:
            print("–û—à–∏–±–∫–∞ –æ—Ç–ø—Ä–∞–≤–∫–∏ –≤–∏–¥–µ–æ:", r.text)
        else:
            print("‚úÖ –í–∏–¥–µ–æ –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ")
            time.sleep(10)

def get_news():
    for feed_url in RSS_FEEDS:
        feed = feedparser.parse(feed_url)
        count = 0
        for entry in feed.entries:
            if count >= 2:
                break
            if entry.link in posted_links:
                continue
            title = entry.title
            description = entry.get("description", "")
            if not is_viral(title, description):
                continue
            posted_links.add(entry.link)
            count += 1
            caption = build_caption(title, description)

            video_url = extract_video_url(entry.link)
            if download_video(video_url):
                send_video_file("video.mp4", caption)
                os.remove("video.mp4")
            else:
                print(f"‚ö†Ô∏è –í–∏–¥–µ–æ –Ω–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å: {video_url}")

if __name__ == "__main__":
    while True:
        try:
            get_news()
            time.sleep(300)  # –∫–∞–∂–¥—ã–µ 5 –º–∏–Ω—É—Ç
        except Exception as e:
            print("–û—à–∏–±–∫–∞ –≤ –æ—Å–Ω–æ–≤–Ω–æ–º —Ü–∏–∫–ª–µ:", e)
            time.sleep(60)
